# æµå¼è¾“å‡º

## æ€»ç»“

æœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•å¯ä»¥ä»å›¾è¿è¡Œä¸­æµå›è¾“å‡ºï¼š

- `value`ï¼šè¿”å›æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåçš„ **å®Œæ•´çŠ¶æ€**
- `updates`ï¼šè¿”å›æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåï¼ŒèŠ‚ç‚¹åç§°å’Œæ›´æ–°å†…å®¹
- `debug`ï¼šè¿”å›å°½å¯èƒ½å¤šä¿¡æ¯çš„è°ƒè¯•äº‹ä»¶ã€‚åŒ…æ‹¬è®¡åˆ’æ‰§è¡ŒèŠ‚ç‚¹çš„ä»»åŠ¡ï¼Œå’Œä»»åŠ¡çš„æ‰§è¡Œç»“æœ
- `messages`ï¼šä¼š **é€ä¸ª token** çš„æµå¼è¿”å› LLM æ¶ˆæ¯ï¼Œä»¥åŠèŠ‚ç‚¹æˆ–ä»»åŠ¡å†…éƒ¨ä»»ä½• LLM è°ƒç”¨ç›¸å…³çš„å…ƒæ•°æ®
- `custom`ï¼šä½¿ç”¨ `StreamWriter` ä»èŠ‚ç‚¹å†…éƒ¨å‘å‡ºè‡ªå®šä¹‰æ•°æ®

## ä¸¾ä¾‹

```python
from typing import TypedDict
from langgraph.graph import StateGraph, START

class State(TypedDict):
  topic: str
  joke: str

def refine_topic(state: State):
  return {"topic": state["topic"] + "å’ŒçŒ«"}


def generate_joke(state: State):
  return {"joke": f"è¿™æ˜¯ä¸€ä¸ªå…³äº{state['topic']}çš„ç¬‘è¯"}

graph = (
  StateGraph(State)
    .add_sequence([refine_topic, generate_joke])
    .add_edge(START, "refine_topic")
    .compile()
)
```

#### `stream_mode="values"`

è¿”å›æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåçš„ **å®Œæ•´çŠ¶æ€**

```python
for chunk in graph.stream({ "topic": "ç‹—" }, stream_mode="values"):
  print(chunk)
```

```
{'topic': 'ç‹—'}
{'topic': 'ç‹—å’ŒçŒ«'}
{'topic': 'ç‹—å’ŒçŒ«', 'joke': 'è¿™æ˜¯ä¸€ä¸ªå…³äºç‹—å’ŒçŒ«çš„ç¬‘è¯'
```

#### `stream_mode="updates"`

è¿”å›æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåï¼ŒèŠ‚ç‚¹åç§°å’Œæ›´æ–°å†…å®¹

```python
for chunk in graph.stream({ "topic": "ç‹—" }, stream_mode="updates"):
  print(chunk)
```

```
{'refine_topic': {'topic': 'ç‹—å’ŒçŒ«'}}
{'generate_joke': {'joke': 'è¿™æ˜¯ä¸€ä¸ªå…³äºç‹—å’ŒçŒ«çš„ç¬‘è¯'}}
```

#### `stream_mode="debug"`

è¿”å›å°½å¯èƒ½å¤šä¿¡æ¯çš„è°ƒè¯•äº‹ä»¶ã€‚åŒ…æ‹¬è®¡åˆ’æ‰§è¡ŒèŠ‚ç‚¹çš„ä»»åŠ¡ï¼Œå’Œä»»åŠ¡çš„æ‰§è¡Œç»“æœ

```python
for chunk in graph.stream({ "topic": "ç‹—" }, stream_mode="debug"):
  print(chunk)
```

```
{'type': 'task', 'timestamp': '2025-05-16T00:44:27.232856+00:00', 'step': 1, 'payload': {'id': 'eb939d5b-06f2-6fec-da89-4f2808c2a433', 'name': 'refine_topic', 'input': {'topic': 'ç‹—'}, 'triggers': ('branch:to:refine_topic',)}}
{'type': 'task_result', 'timestamp': '2025-05-16T00:44:27.233889+00:00', 'step': 1, 'payload': {'id': 'eb939d5b-06f2-6fec-da89-4f2808c2a433', 'name': 'refine_topic', 'error': None, 'result': [('topic', 'ç‹—å’ŒçŒ«')], 'interrupts': []}}
{'type': 'task', 'timestamp': '2025-05-16T00:44:27.233889+00:00', 'step': 2, 'payload': {'id': '386a0482-ec26-7c4a-b53e-d279a9d1e4e2', 'name': 'generate_joke', 'input': {'topic': 'ç‹—å’ŒçŒ«'}, 'triggers': ('branch:to:generate_joke',)}}
{'type': 'task_result', 'timestamp': '2025-05-16T00:44:27.233889+00:00', 'step': 2, 'payload': {'id': '386a0482-ec26-7c4a-b53e-d279a9d1e4e2', 'name': 'generate_joke', 'error': None, 'result': [('joke', 'è¿™æ˜¯ä¸€ä¸ª å…³äºç‹—å’ŒçŒ«çš„ç¬‘è¯')], 'interrupts': []}}
```

#### `stream_mode="messages"`

ä¼š **é€ä¸ª token** çš„æµå¼è¿”å› LLM æ¶ˆæ¯ï¼Œä»¥åŠèŠ‚ç‚¹æˆ–ä»»åŠ¡å†…éƒ¨ä»»ä½• LLM è°ƒç”¨ç›¸å…³çš„å…ƒæ•°æ®

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini")

def generate_joke(state: State):
  res = llm.invoke(
    [HumanMessage(content=f"ç”Ÿæˆä¸€ä¸ªå…³äº{state['topic']}çš„ç¬‘è¯")]
  )
  return {"joke": res.content}
```

```python
for message_chunk, metadata in graph.stream({ "topic": "ç‹—" }, stream_mode="messages"):
  if message_chunk.content:
    print(message_chunk.content, end="|", flush=True)
```

```
å¥½çš„|ï¼Œ|è¿™é‡Œ|æœ‰ä¸€ä¸ª|å…³äº|ç‹—|å’Œ|çŒ«|çš„|ç»å…¸|ç¬‘è¯|ï¼š

|---

|**|ç‹—|å’Œ|çŒ«|çš„|é¢è¯•|**|  

|ä¸€å®¶|å…¬å¸|åŒæ—¶|é¢è¯•|äº†ä¸€åª|ç‹—|å’Œ|ä¸€åª|çŒ«|ã€‚|  
|HR|é—®|ç‹—|ï¼šâ€œ|ä½ æœ‰ä»€ä¹ˆ|æŠ€èƒ½|ï¼Ÿâ€|  
|ç‹—|éª„å‚²|åœ°è¯´|ï¼šâ€œ|æˆ‘ä¼š|å¿ è¯š|ã€|çœ‹|å®¶|ã€|æ¡|é£|ç›˜|ï¼Œ|è¿˜èƒ½|å“„|ä¸»äºº|å¼€å¿ƒ|ï¼â€|  
|HR|ç‚¹ç‚¹å¤´|ï¼Œ|åˆé—®|çŒ«|ï¼šâ€œ|ä½ å‘¢|ï¼Ÿâ€|  
|çŒ«|æ·¡å®š|åœ°|èˆ”|äº†|èˆ”|çˆªå­|è¯´|ï¼šâ€œ|æˆ‘|â€¦â€¦|ä¼š|å¼€|è§†é¢‘|ä¼šè®®|ã€‚â€|  
|HR|ç–‘æƒ‘|ï¼šâ€œ|å•Š|ï¼Ÿâ€|  
|çŒ«|æŒ‡äº†æŒ‡|ç”µè„‘|ï¼šâ€œ|ä½ |é”®ç›˜|ä¸Š|ç°åœ¨|å…¨æ˜¯|æˆ‘çš„|æ¯›|ã€‚â€|  

|---|  

|ï¼ˆ|ç¬‘|ç‚¹|ï¼š|çŒ«|ç”¨|â€œ|æ‰|æ¯›|â€|æš—ç¤º|è‡ªå·±|æ—©å·²|â€œ|å é¢†|â€|åŠå…¬|è®¾å¤‡|ï¼Œ|è€Œ|ç‹—|è¿˜åœ¨|åŠªåŠ›|å±•ç¤º|ä¼ ç»Ÿ|æŠ€èƒ½|ğŸ˜‚|ï¼‰|  

|éœ€è¦|å…¶ä»–|é£æ ¼|çš„ç¬‘|è¯|å¯ä»¥|å‘Šè¯‰æˆ‘|å“¦|ï¼|
```

```python
print(metadata)
```

```
{
'langgraph_step': 2,
'langgraph_node': 'generate_joke',
'langgraph_triggers': ('branch:to:generate_joke',),
'langgraph_path': ('__pregel_pull', 'generate_joke'),
'langgraph_checkpoint_ns': 'generate_joke:3c066034-a385-6d5f-18bb-e7ca9fe140f9',
'checkpoint_ns': 'generate_joke:3c066034-a385-6d5f-18bb-e7ca9fe140f9',
'ls_provider': 'openai',
'ls_model_name': 'deepseek-chat',
'ls_model_type': 'chat',
'ls_temperature': 0.0,
'ls_max_tokens': 1024
}
```

