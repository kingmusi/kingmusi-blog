# 输出特定的流式消息

## 从特定节点流式输出

通过流式元数据中的 `langgraph_node` 字段过滤输出

```python
for msg, metadata in graph.stream(
    inputs,
    stream_mode="messages"
):
    # 从特定的节点 "node_a" 获取消息
    if metadata["langgraph_node"] == "node_a":
        print(msg)
```

## 同一节点特定 `llm` 流式输出

定义`llm`时，带上 `tags` 进行标记

```python
from langchain_openai import ChatOpenAI

joke_model = ChatOpenAI(model="gpt-4o-mini", tags=["joke"])
poem_model = ChatOpenAI(model="gpt-4o-mini", tags=["poem"])
```

同一节点使用两个 `llm`

```python
async def call_model(state, config):
    topic = state["topic"]
    joke_response = await joke_model.ainvoke(
        HumanMessage(content=f"生成一个关于{state['topic']}的笑话"),
        config,
    )
    poem_response = await poem_model.ainvoke(
         HumanMessage(content=f"生成一个关于{state['topic']}的诗歌"),
        config,
    )
    return {"joke": joke_response.content, "poem": poem_response.content}
```

通过 `tags` 过滤特定的 `llm` 输出

```python
async for msg, metadata in graph.astream(
    {"topic": "猫"},
    stream_mode="messages",
):
    if msg.content and "joke" in metadata.get("tags", []):
        print(msg.content, end="|", flush=True)
```

