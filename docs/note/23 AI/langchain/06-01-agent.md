# agent

## åˆ›å»ºagent

1. åˆ›å»ºæç¤ºè¯

```python
from langchain import hub

prompt = hub.pull("hwchase17/openai-functions-agent")
print(prompt)
```

> ```python
> [
>   SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),
>   MessagesPlaceholder(variable_name='chat_history', optional=True),
>   HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),
>   MessagesPlaceholder(variable_name='agent_scratchpad')
> ]
> ```

2. æ„å»ºagent

```python
from langchain.agents import create_tool_calling_agent

agent = create_tool_calling_agent(llm, tools, prompt)
```

3. å°† Agent ä¸ AgentExecutor ä¸­çš„å·¥å…·ç»“åˆèµ·æ¥
   - AgentExecutorå°†é‡å¤è°ƒç”¨ä»£ç†å¹¶æ‰§è¡Œå·¥å…·

```python
from langchain.agents import AgentExecutor

agent_executor = AgentExecutor(agent=agent, tools=tools)
```

4. è¿è¡Œ

```python
respose = agent_executor.invoke({ "input": "ä½ å¥½" })
```

```
{'input': 'ä½ å¥½', 'output': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}
```

5. æ•´ä½“ä»£ç 

:::demo config={"packages":["langchain","langchain_deepseek"]}
```python
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_deepseek import ChatDeepSeek
from langchain_core.prompts import SystemMessagePromptTemplate, MessagesPlaceholder, PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.tools import tool

@tool
def get_weather(city: str) -> str:
  """è·å–å¤©æ°”çŠ¶å†µ"""
  return "å¤©æ™´æ™´æœ—"

llm = ChatDeepSeek(model_name="deepseek-chat", api_key="your_api_key")
tools = [get_weather]
prompt = ChatPromptTemplate.from_messages([
  SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),
  MessagesPlaceholder(variable_name='chat_history', optional=True),
  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),
  MessagesPlaceholder(variable_name='agent_scratchpad')
])

agent = create_tool_calling_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)
respose = agent_executor.invoke({ "input": "ä½ å¥½" })
print(respose)
```
:::

## æ·»åŠ è®°å¿†

1. åˆ›å»ºä¼šè¯è®°å¿†å­˜å‚¨æœç´¢å‡½æ•°

```python
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

store = {}
def get_session_history(session_id: str) -> BaseChatMessageHistory:
 	if session_id not in store:
 		store[session_id] = ChatMessageHistory()
 	return store[session_id]
```

2. ä½¿ç”¨ `RunnableWithMessageHistory` æ„å»º

```python
agent_with_history = RunnableWithMessageHistory(
    agent_executor,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history"
)
```

3. è¿è¡Œ

```python
response = agent_with_history.invoke(
    {"input": "ä½ å¥½å“‡ï¼Œæˆ‘å«kingmusi"},
    config={"configurable": {"session_id": "123"}}
)
print(response)

response = agent_with_history.invoke(
    {"input": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"},
    config={"configurable": {"session_id": "123"}}
)
print(response)
```

```
{'input': 'ä½ å¥½å“‡ï¼Œæˆ‘å«kingmusi', 'chat_history': [], 'output': 'ä½ å¥½ï¼ŒKingmusiï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š'}
{'input': 'æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ', 'chat_history': [HumanMessage(content='ä½ å¥½å“‡ï¼Œæˆ‘å«kingmusi', additional_kwargs={}, response_metadata={}), AIMessage(content='ä½ å¥½ï¼ŒKingmusiï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š', additional_kwargs={}, response_metadata={})], 'output': 'ä½ åˆšåˆšå‘Šè¯‰æˆ‘ä½ çš„åå­—æ˜¯ **Kingmusi**ï¼æ²¡é”™å§ï¼ŸğŸ˜„'}
```

