# 向量数据库

## 介绍
向量数据库（Vector Database），也叫矢量数据库，主要用来存储和处理向量数据

向量数据库的主要特点是高效存储与检索。利用索引技术和向量检索算法能实现高维大数据下的快速响应。向量数据库也是一种数据库，除了要管理向量数据外，还是支持对传统结构化数据的管理。实际使用时，有很多场景会同时对向量字段和结构化字段进行过滤检索，这对向量数据库来说也是一种挑战。

## [Chroma](https://docs.trychroma.com/docs/overview/introduction)

#### 安装

```shell
pip install langchain-chroma
```

#### 基础查询

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 加载文档
loader = TextLoader("assets/test.txt", encoding="utf-8")
documents = loader.load()
# 切割成片段
text_splitter = RecursiveCharacterTextSplitter(
  separators=[
    "\n\n",
    "\n",
    " ",
    ".",
    ",",
    "\u200b", # 零宽空格
    "\uff0c", # 全角逗号
    "\u3001", # 表意逗号
    "\uff0e", # 全角句号
    "\u3002", # 表意句号
    "",
  ],
  chunk_size=100,
  chunk_overlap=20
)
docs = text_splitter.split_documents(documents)
# 创建向量数据库
db = Chroma.from_documents(docs, OpenAIEmbeddings())
# 查询
query = '今天天气怎么样'
docs = db.similarity_search(query)
print(docs[0].page_content)

# 带分数的相似性搜索
# 返回的距离分数是余弦距离。因此，分数越低越好
docs = db.similarity_search_with_score(query)
```

> 将数据保存到文件中，并从对应文件中重新读取数据
>
> ```python
> db = Chroma.from_documents(
>   docs,
>   get_text_embedding_3_small(),
>   # 保存到cache/chroma_db下，并从cache/chroma_db下读取数据
>   persist_directory="cache/chroma_db"
> )
> ```

#### 精确控制

可以创建一个 Chroma 客户端并将其传递给 LangChain

可以指定要让 LangChain 使用的集合名称

```python
import chromadb
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document

presistent_client = chromadb.PersistentClient(path="cache/chroma_db")
collection = presistent_client.get_or_create_collection("test")

# 创建实例
langchain_chroma = Chroma(
  client=presistent_client,
  collection_name="test",
  embedding_function=get_text_embedding_3_small()
)

# 添加数据，并规定对应id
documents = [
    Document(page_content="a", metadata={"source": "initial"}),
    Document(page_content="b", metadata={"source": "initial"}),
    Document(page_content="c", metadata={"source": "initial"})
]
langchain_chroma.add_documents(documents, ids=["1", "2", "3"])
```

查询当前数据数量

```python
langchain_chroma._collection.count()
```

查询对应 id 具体数据

```python
langchain_chroma.get(ids=["1"])
# {'ids': ['1'], 'embeddings': None, 'documents': ['a'], 'uris': None, 'data': None, 'metadatas': [None], 'included': [<IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}
```

更新数据

```python
langchain_chroma.update_document("1", Document(page_content="aa", metadata={"source": "updated"}))
langchain_chroma.get(ids=["1"])
# {'ids': ['1'], 'embeddings': None, 'documents': ['aa'], 'uris': None, 'data': None, 'metadatas': [{'source': 'updated'}], 'included': [<IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}
```

删除数据

```python
langchain_chroma.delete(ids=["1"])
```

## [FAISS](https://faiss.ai/)

#### 安装

```shell
pip install langchain-community faiss-cpu
```

> 如果想启用 GPU 的版本，安装 `faiss-gpu`

#### 基础查询

```python
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 加载文档
loader = TextLoader("assets/tal.txt", encoding="utf-8")
documents = loader.load()
# 切割成片段
text_splitter = RecursiveCharacterTextSplitter(
  separators=[
    "\n\n",
    "\n",
    " ",
    ".",
    ",",
    "\u200b", # 零宽空格
    "\uff0c", # 全角逗号
    "\u3001", # 表意逗号
    "\uff0e", # 全角句号
    "\u3002", # 表意句号
    "",
  ],
  chunk_size=100,
  chunk_overlap=20
)
docs = text_splitter.split_documents(documents)
# 创建向量数据库
db = FAISS.from_documents(docs, get_text_embedding_3_small())
# 查询
query = '好未来的业务都有哪些？'
docs = db.similarity_search(query)
print(docs[0].page_content)

# 带分数的相似性搜索
# 返回的距离分数是余弦距离。因此，分数越低越好
docs = db.similarity_search_with_score(query)
```

> 将数据保存在文件中，并访问文件数据
>
> ```python
> #保存索引
> db.save_local("faiss_index")
> #读取索引
> new_db = FAISS.load_local("faiss_index", embeddings,allow_dangerous_deserialization=True)
> ```

## MMR

MMR（Maximal Marginal Relevance，最 大边际相关性）是一种信息检索和文本摘要技术，用于在选择文档或文本片段时平衡相关性和多样 性。其主要目的是在检索结果中既包含与查询高度相关的内容，又避免结果之间的高度冗余。

```python
retriever = db.as_retriever(search_type="mmr")
docs = retriever.invoke(query)
```



